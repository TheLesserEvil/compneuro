%% AUTHOR : Casper van Elteren
function main()
maxIter = 100;
test = 1;
if test
    % 2 dimensional case for error debugging!
    n = 2;
    p = 100;
    % for testing purposed set this to 1
    linSep = 1;
    
    % show the 2 dimension case [testing]
    [x,t]= genData(n, p , linSep);
    [w,c] = pla(n,p,x,t, linSep, maxIter);
    plotSep(w,x,t,n);
end

% show the fraction of completion as function of p
n = 50;
p = [2:1:3*n];

for pi = 1:numel(p)
    linSep = 0;
    [x,t] = genData(n,p(pi), linSep);
    [~,c] = pla(n, p(pi), x, t, 1e-3, maxIter);
%     dd(pi) = 0;
%     for j = 0:n-1
%         try
%             dd(pi) = dd(pi) + nchoosek(p(pi)-1, j);
%         catch
%             continue
%         end
%     end
%     
    cc(pi) = c;
end
figure(2);  clf()
plot(p, cc,'-o')
xlabel('Number of patterns'); ylabel('Fraction of convergence');


end

function plotSep(w,x,t,n)
if n == 2
    l = linspace(-1,1);
    % plot the line a x + b , with a = dxdy, b = dydz (due to bias)
    dxdy =  -w(2)/w(3);
    b    =  -w(1)/w(3);
    labels = {'1','-1','classification line'};
    figure(1); clf();hold
    
    % label 1 data
    tmpx = x(2,t == 1);
    tmpy = x(3, t == 1);
    % label -1 data
    tmpxx = x(2, t == -1);
    tmpyy = x(3, t == -1);
    
    % plot
    plot(tmpx, tmpy,'or',...
        tmpxx, tmpyy, 'ob',...
        l, dxdy * l + b, '--')
else
    disp('Too many dimensions! Try with 2');
    
end
end

function [w,c] = pla(n, p, x, t, eta, maxiter)
% assuming that bias term is added
% init weights between -1, 1
w = rand(n+1,1)*2 - 1;

% convergence vector
c = zeros(p,1);
idx =1;
% keep going until all paterns are converged
while not(all(c))
    % for all patterns
    for j = 1:p
        inp = x(:,j);
        % compute the activation [binary neuron classication]
%         tmp = sign(w' * inp);
        % if target is not achieved update weights
%         if tmp ~= t(j)
        tmp = w' * inp;
        if tmp < 0
            dw = eta * (t(j)- tmp) * inp;
            w = w + dw;
            % converged
        else
            c(j) = true;
        end
    end
    
    idx = idx +1;
    % if converging is not possible stop
    if idx > maxiter
        break
    end
end
% number of converged patterns
c = mean(c);
end

function [x,t] = genData(n, p, sep)
% generates random linearly separable data, or random data
w = rand(n+1,1)*2 - 1;
% generate data
for i = 1:p
    % add 1 for bias term
    tmp = [1; rand(n,1)];
    x(:, i) = tmp;
    % make sure they are linearly separable
    if sep
        t(i)  = sign(w' * tmp);
        
        % else just put random targets
        % note this may not lead to convergence!
    else
        if rand()*2 -1 > 0
            t(i) = 1;
        else
            t(i) = -1;
        end
    end
end
end

%
% %% start of
%     case 'mnist',
%         load mnistAll.mat
%         Xmnist=mnist.train_images;
%         ymnist=mnist.train_labels;
%
%         X3=Xmnist(:,:,find(ymnist==3)); % images of 3's
%         X7=Xmnist(:,:,find(ymnist==7)); % images of 7's
%
%         n=size(X3,1).^2;
%         x3=-reshape(X3,n,size(X3,3));	% input data of 3's multiplied by class label -1
%         x7=reshape(X7,n,size(X7,3));		% input data of 7's multiplied by class label
%         x3(n+1,:)=-1;
%         x7(n+1,:)=1;
%         x=[x3,x7]';
%         x=double(x);	% matlab does not like the mnist data format
%         p=size(x,1);
%
% end;
% end
